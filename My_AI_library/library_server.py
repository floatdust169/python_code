from flask import Flask, request, jsonify
from flask_cors import CORS
import os
import json
import uuid
from datetime import datetime
from docx import Document  
import PyPDF2
import jieba  # æ–°å¢ï¼šç”¨äºä¸­æ–‡åˆ†è¯
import re
from collections import Counter
from volcenginesdkarkruntime import Ark  # æ–°å¢ï¼šè±†åŒ…å¤§æ¨¡å‹SDK

# åˆå§‹åŒ–Flaskåº”ç”¨
app = Flask(__name__)

# é…ç½®CORSï¼Œå…è®¸æ‰€æœ‰åŸŸåè®¿é—®
CORS(app, 
     origins=["*"],  # å…è®¸æ‰€æœ‰æ¥æº
     methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],  # å…è®¸çš„HTTPæ–¹æ³•ï¼ˆæ–°å¢PUTï¼‰
     allow_headers=["Content-Type", "Authorization"]  # å…è®¸çš„è¯·æ±‚å¤´
)

# é…ç½®
UPLOAD_FOLDER = 'uploads'
DATA_FOLDER = 'data'  # å­˜å‚¨çŸ¥è¯†åº“æ•°æ®
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(DATA_FOLDER, exist_ok=True)
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['DATA_FOLDER'] = DATA_FOLDER
ALLOWED_EXTENSIONS = {'txt', 'docx', 'pdf'}

# æ•°æ®æ–‡ä»¶è·¯å¾„
KNOWLEDGE_BASES_FILE = os.path.join(DATA_FOLDER, 'knowledge_bases.json')
DOCUMENTS_FILE = os.path.join(DATA_FOLDER, 'documents.json')

# è±†åŒ…å¤§æ¨¡å‹é…ç½®
ARK_API_KEY = "aba732fd-b2a9-4e60-819d-64e0b5e622fe"
ARK_MODEL = "doubao-1-5-pro-32k-250115"

# åˆå§‹åŒ–è±†åŒ…å®¢æˆ·ç«¯
ark_client = Ark(api_key=ARK_API_KEY)

# å†…å­˜å­˜å‚¨
knowledge_bases = []
documents = []

# åˆå§‹åŒ–æ•°æ®å­˜å‚¨
def init_data_storage():
    global knowledge_bases, documents
    
    # åŠ è½½çŸ¥è¯†åº“æ•°æ®
    if os.path.exists(KNOWLEDGE_BASES_FILE):
        try:
            with open(KNOWLEDGE_BASES_FILE, 'r', encoding='utf-8') as f:
                knowledge_bases = json.load(f)
            print(f"âœ… å·²åŠ è½½ {len(knowledge_bases)} ä¸ªçŸ¥è¯†åº“")
        except Exception as e:
            print(f"âŒ åŠ è½½çŸ¥è¯†åº“æ•°æ®å¤±è´¥: {e}")
            knowledge_bases = []
    else:
        knowledge_bases = []
        save_knowledge_bases()
    
    # åŠ è½½æ–‡æ¡£æ•°æ®
    if os.path.exists(DOCUMENTS_FILE):
        try:
            with open(DOCUMENTS_FILE, 'r', encoding='utf-8') as f:
                documents = json.load(f)
            print(f"âœ… å·²åŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£")
        except Exception as e:
            print(f"âŒ åŠ è½½æ–‡æ¡£æ•°æ®å¤±è´¥: {e}")
            documents = []
    else:
        documents = []
        save_documents()

# ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶
def save_knowledge_bases():
    try:
        with open(KNOWLEDGE_BASES_FILE, 'w', encoding='utf-8') as f:
            json.dump(knowledge_bases, f, ensure_ascii=False, indent=2, default=str)
    except Exception as e:
        print(f"âŒ ä¿å­˜çŸ¥è¯†åº“æ•°æ®å¤±è´¥: {e}")

def save_documents():
    try:
        with open(DOCUMENTS_FILE, 'w', encoding='utf-8') as f:
            json.dump(documents, f, ensure_ascii=False, indent=2, default=str)
    except Exception as e:
        print(f"âŒ ä¿å­˜æ–‡æ¡£æ•°æ®å¤±è´¥: {e}")

# ------------------------------
# 2. çŸ¥è¯†åº“ç®¡ç†æ¥å£
# ------------------------------

# è·å–æ‰€æœ‰çŸ¥è¯†åº“åˆ—è¡¨
@app.route('/api/knowledge', methods=['GET'])
def get_knowledge_bases():
    try:
        return jsonify(knowledge_bases), 200
    except Exception as e:
        print(f"è·å–çŸ¥è¯†åº“åˆ—è¡¨å¤±è´¥: {e}")
        return jsonify({'error': f'è·å–çŸ¥è¯†åº“åˆ—è¡¨å¤±è´¥: {str(e)}'}), 500

# åˆ›å»ºçŸ¥è¯†åº“
@app.route('/api/knowledge', methods=['POST'])
def create_knowledge():
    try:
        data = request.get_json()
        if not data or 'åº“å' not in data:
            return jsonify({'error': 'ç¼ºå°‘åº“å'}), 400
        
        # æ£€æŸ¥æ˜¯å¦é‡å
        if any(kb['name'] == data['åº“å'] for kb in knowledge_bases):
            return jsonify({'error': 'çŸ¥è¯†åº“åç§°å·²å­˜åœ¨'}), 400
        
        # åˆ›å»ºæ–°çŸ¥è¯†åº“
        knowledge_id = str(uuid.uuid4())
        knowledge = {
            '_id': knowledge_id,
            'name': data['åº“å'],
            'description': data.get('åº“æè¿°', ''),
            'prompt': data.get('æç¤ºè¯', 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ¥è¯†åº“åŠ©æ‰‹ï¼Œè¯·æ ¹æ®æä¾›çš„æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚'),  # æ–°å¢æç¤ºè¯å­—æ®µ
            'create_time': datetime.now().isoformat(),
            'document_count': 0
        }
        
        # æ·»åŠ åˆ°å†…å­˜å¹¶ä¿å­˜åˆ°æ–‡ä»¶
        knowledge_bases.append(knowledge)
        save_knowledge_bases()
        
        print(f"âœ… åˆ›å»ºçŸ¥è¯†åº“æˆåŠŸ: {data['åº“å']} (ID: {knowledge_id})")
        return jsonify({
            'id': knowledge_id,
            'message': 'çŸ¥è¯†åº“åˆ›å»ºæˆåŠŸ'
        }), 201
    except Exception as e:
        print(f"åˆ›å»ºçŸ¥è¯†åº“å¤±è´¥: {e}")
        return jsonify({'error': f'åˆ›å»ºçŸ¥è¯†åº“å¤±è´¥: {str(e)}'}), 500

# åˆ é™¤çŸ¥è¯†åº“
@app.route('/api/knowledge', methods=['DELETE'])
def delete_knowledge():
    try:
        data = request.get_json()
        if not data or 'id' not in data:
            return jsonify({'error': 'ç¼ºå°‘çŸ¥è¯†åº“ID'}), 400
        
        knowledge_id = data['id']
        
        # æŸ¥æ‰¾è¦åˆ é™¤çš„çŸ¥è¯†åº“
        knowledge_to_delete = None
        for i, kb in enumerate(knowledge_bases):
            if kb['_id'] == knowledge_id:
                knowledge_to_delete = knowledge_bases.pop(i)
                break
        
        if not knowledge_to_delete:
            return jsonify({'error': 'çŸ¥è¯†åº“ä¸å­˜åœ¨'}), 404
        
        # åˆ é™¤ç›¸å…³æ–‡æ¡£æ–‡ä»¶
        docs_to_remove = []
        for i, doc in enumerate(documents):
            if doc['knowledge_id'] == knowledge_id:
                # åˆ é™¤æœåŠ¡å™¨ä¸Šçš„æ–‡ä»¶
                file_path = os.path.join(app.config['UPLOAD_FOLDER'], doc['file_name'])
                if os.path.exists(file_path):
                    os.remove(file_path)
                    print(f"ğŸ—‘ï¸ åˆ é™¤æ–‡ä»¶: {doc['file_name']}")
                docs_to_remove.append(i)
        
        # ä»åå¾€å‰åˆ é™¤æ–‡æ¡£è®°å½•ï¼ˆé¿å…ç´¢å¼•å˜åŒ–ï¼‰
        for i in reversed(docs_to_remove):
            documents.pop(i)
        
        # ä¿å­˜æ›´æ–°åçš„æ•°æ®
        save_knowledge_bases()
        save_documents()
        
        print(f"âœ… åˆ é™¤çŸ¥è¯†åº“æˆåŠŸ: {knowledge_to_delete['name']}")
        return jsonify({'message': 'çŸ¥è¯†åº“åˆ é™¤æˆåŠŸ'}), 200
    except Exception as e:
        print(f"åˆ é™¤çŸ¥è¯†åº“å¤±è´¥: {e}")
        return jsonify({'error': f'åˆ é™¤çŸ¥è¯†åº“å¤±è´¥: {str(e)}'}), 500

# æ›´æ–°çŸ¥è¯†åº“ä¿¡æ¯ï¼ˆåŒ…æ‹¬æç¤ºè¯ï¼‰
@app.route('/api/knowledge/<knowledge_id>', methods=['PUT'])
def update_knowledge(knowledge_id):
    try:
        data = request.get_json()
        if not data:
            return jsonify({'error': 'è¯·æ±‚æ•°æ®ä¸ºç©º'}), 400
        
        # æŸ¥æ‰¾è¦æ›´æ–°çš„çŸ¥è¯†åº“
        knowledge_base = None
        for kb in knowledge_bases:
            if kb['_id'] == knowledge_id:
                knowledge_base = kb
                break
        
        if not knowledge_base:
            return jsonify({'error': 'çŸ¥è¯†åº“ä¸å­˜åœ¨'}), 404
        
        # æ›´æ–°çŸ¥è¯†åº“ä¿¡æ¯
        if 'name' in data:
            # æ£€æŸ¥æ–°åç§°æ˜¯å¦é‡å¤
            if any(kb['name'] == data['name'] and kb['_id'] != knowledge_id for kb in knowledge_bases):
                return jsonify({'error': 'çŸ¥è¯†åº“åç§°å·²å­˜åœ¨'}), 400
            knowledge_base['name'] = data['name']
        
        if 'description' in data:
            knowledge_base['description'] = data['description']
        
        if 'prompt' in data:
            knowledge_base['prompt'] = data['prompt']
        
        knowledge_base['update_time'] = datetime.now().isoformat()
        
        # ä¿å­˜æ›´æ–°
        save_knowledge_bases()
        
        print(f"âœ… æ›´æ–°çŸ¥è¯†åº“æˆåŠŸ: {knowledge_base['name']}")
        return jsonify({
            'message': 'çŸ¥è¯†åº“æ›´æ–°æˆåŠŸ',
            'knowledge_base': knowledge_base
        }), 200
    except Exception as e:
        print(f"æ›´æ–°çŸ¥è¯†åº“å¤±è´¥: {e}")
        return jsonify({'error': f'æ›´æ–°çŸ¥è¯†åº“å¤±è´¥: {str(e)}'}), 500

# æ–°å¢ï¼šä¸“é—¨ç”¨äºæ›´æ–°æç¤ºè¯çš„æ¥å£
@app.route('/api/knowledge/<knowledge_id>/prompt', methods=['PUT'])
def update_knowledge_prompt(knowledge_id):
    try:
        data = request.get_json()
        if not data or 'prompt' not in data:
            return jsonify({'error': 'ç¼ºå°‘æç¤ºè¯å‚æ•°'}), 400
        
        # æŸ¥æ‰¾è¦æ›´æ–°çš„çŸ¥è¯†åº“
        knowledge_base = None
        for kb in knowledge_bases:
            if kb['_id'] == knowledge_id:
                knowledge_base = kb
                break
        
        if not knowledge_base:
            return jsonify({'error': 'çŸ¥è¯†åº“ä¸å­˜åœ¨'}), 404
        
        # æ›´æ–°æç¤ºè¯
        knowledge_base['prompt'] = data['prompt']
        knowledge_base['update_time'] = datetime.now().isoformat()
        
        # ä¿å­˜æ›´æ–°
        save_knowledge_bases()
        
        print(f"âœ… æ›´æ–°çŸ¥è¯†åº“æç¤ºè¯æˆåŠŸ: {knowledge_base['name']}")
        return jsonify({
            'message': 'æç¤ºè¯æ›´æ–°æˆåŠŸ',
            'prompt': knowledge_base['prompt']
        }), 200
    except Exception as e:
        print(f"æ›´æ–°æç¤ºè¯å¤±è´¥: {e}")
        return jsonify({'error': f'æ›´æ–°æç¤ºè¯å¤±è´¥: {str(e)}'}), 500

# æ–°å¢ï¼šä½¿ç”¨POSTæ–¹æ³•æ›´æ–°æç¤ºè¯ï¼ˆå…¼å®¹æ–¹æ¡ˆï¼‰
@app.route('/api/knowledge/update_prompt', methods=['POST'])
def update_prompt_post():
    try:
        data = request.get_json()
        if not data or 'id' not in data or 'prompt' not in data:
            return jsonify({'error': 'ç¼ºå°‘å¿…è¦å‚æ•°ï¼ˆidå’Œpromptï¼‰'}), 400
        
        knowledge_id = data['id']
        prompt = data['prompt']
        
        # æŸ¥æ‰¾è¦æ›´æ–°çš„çŸ¥è¯†åº“
        knowledge_base = None
        for kb in knowledge_bases:
            if kb['_id'] == knowledge_id:
                knowledge_base = kb
                break
        
        if not knowledge_base:
            return jsonify({'error': 'çŸ¥è¯†åº“ä¸å­˜åœ¨'}), 404
        
        # æ›´æ–°æç¤ºè¯
        knowledge_base['prompt'] = prompt
        knowledge_base['update_time'] = datetime.now().isoformat()
        
        # ä¿å­˜æ›´æ–°
        save_knowledge_bases()
        
        print(f"âœ… æ›´æ–°çŸ¥è¯†åº“æç¤ºè¯æˆåŠŸ: {knowledge_base['name']}")
        return jsonify({
            'message': 'æç¤ºè¯æ›´æ–°æˆåŠŸ',
            'prompt': knowledge_base['prompt']
        }), 200
    except Exception as e:
        print(f"æ›´æ–°æç¤ºè¯å¤±è´¥: {e}")
        return jsonify({'error': f'æ›´æ–°æç¤ºè¯å¤±è´¥: {str(e)}'}), 500

# ------------------------------
# 4. æ–‡ä»¶ä¸Šä¼ ä¸å¤„ç†æ¥å£
# ------------------------------

# æ£€æŸ¥æ–‡ä»¶ç±»å‹æ˜¯å¦å…è®¸
def allowed_file(filename):
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

# è§£ææ–‡ä»¶å†…å®¹
def parse_file(file_path, file_type):
    content = ""
    try:
        if file_type == 'txt':
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        
        elif file_type == 'docx':
            doc = Document(file_path)
            content = '\n'.join([para.text for para in doc.paragraphs])
        
        elif file_type == 'pdf':
            with open(file_path, 'rb') as f:
                reader = PyPDF2.PdfReader(f)
                content = '\n'.join([page.extract_text() for page in reader.pages])
        
    except Exception as e:
        print(f"è§£ææ–‡ä»¶å¤±è´¥: {e}")
    return content

# ä¸Šä¼ æ–‡ä»¶åˆ°æŒ‡å®šçŸ¥è¯†åº“
@app.route('/api/upload', methods=['POST'])
def upload_file():
    try:
        knowledge_id = request.form.get('knowledge_id')
        if not knowledge_id:
            return jsonify({'error': 'ç¼ºå°‘çŸ¥è¯†åº“ID'}), 400
        
        # æ£€æŸ¥çŸ¥è¯†åº“æ˜¯å¦å­˜åœ¨
        knowledge_base = None
        for kb in knowledge_bases:
            if kb['_id'] == knowledge_id:
                knowledge_base = kb
                break
        
        if not knowledge_base:
            return jsonify({'error': 'çŸ¥è¯†åº“ä¸å­˜åœ¨'}), 404
        
        if 'file' not in request.files:
            return jsonify({'error': 'æœªä¸Šä¼ æ–‡ä»¶'}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'æœªé€‰æ‹©æ–‡ä»¶'}), 400
        
        if file and allowed_file(file.filename):
            # ä¿å­˜æ–‡ä»¶åˆ°æœåŠ¡å™¨
            timestamp = datetime.now().timestamp()
            filename = f"{timestamp}_{file.filename}"
            file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
            file.save(file_path)
            
            # è§£ææ–‡ä»¶å†…å®¹
            file_type = filename.rsplit('.', 1)[1].lower()
            content = parse_file(file_path, file_type)
            
            # åˆ›å»ºæ–‡æ¡£è®°å½•
            file_id = str(uuid.uuid4())
            document = {
                '_id': file_id,
                'knowledge_id': knowledge_id,
                'file_name': filename,
                'original_name': file.filename,
                'file_type': file_type,
                'file_size': os.path.getsize(file_path),
                'upload_time': datetime.now().isoformat(),
                'content': content[:10000]  # å­˜å‚¨å‰10000å­—ç¬¦
            }
            
            # æ·»åŠ åˆ°å†…å­˜å¹¶ä¿å­˜
            documents.append(document)
            save_documents()
            
            # æ›´æ–°çŸ¥è¯†åº“æ–‡æ¡£è®¡æ•°
            knowledge_base['document_count'] += 1
            save_knowledge_bases()
            
            print(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {file.filename} -> {knowledge_base['name']}")
            return jsonify({
                'message': 'æ–‡ä»¶ä¸Šä¼ æˆåŠŸ',
                'file_id': file_id
            }), 201
        
        return jsonify({'error': 'ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹'}), 400
    except Exception as e:
        print(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {e}")
        return jsonify({'error': f'æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}'}), 500

# è·å–çŸ¥è¯†åº“ä¸­çš„æ–‡æ¡£åˆ—è¡¨
@app.route('/api/knowledge/<knowledge_id>/documents', methods=['GET'])
def get_knowledge_documents(knowledge_id):
    try:
        # æŸ¥æ‰¾å±äºè¯¥çŸ¥è¯†åº“çš„æ–‡æ¡£
        kb_documents = [doc for doc in documents if doc['knowledge_id'] == knowledge_id]
        
        # è¿”å›æ–‡æ¡£åˆ—è¡¨ï¼ˆä¸åŒ…å«contentå­—æ®µï¼Œå‡å°‘æ•°æ®ä¼ è¾“ï¼‰
        document_list = []
        for doc in kb_documents:
            doc_info = {
                '_id': doc['_id'],
                'original_name': doc['original_name'],
                'file_type': doc['file_type'],
                'file_size': doc['file_size'],
                'upload_time': doc['upload_time']
            }
            document_list.append(doc_info)
        
        return jsonify(document_list), 200
    except Exception as e:
        print(f"è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {e}")
        return jsonify({'error': f'è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {str(e)}'}), 500

# æ–°å¢ï¼šæ™ºèƒ½é—®ç­”ç±» (é›†æˆask.pyçš„åŠŸèƒ½)
class IntelligentQA:
    def __init__(self):
        pass
    
    def preprocess_text(self, text):
        """æ–‡æœ¬é¢„å¤„ç†ï¼šåˆ†è¯å¹¶è¿‡æ»¤"""
        if not text:
            return []
        words = jieba.lcut(str(text).lower())
        # è¿‡æ»¤æ‰é•¿åº¦å°äº2çš„è¯ï¼Œä¿ç•™ä¸­æ–‡å’Œå­—æ¯æ•°å­—
        words = [word for word in words if len(word) >= 2 and (word.isalnum() or any('\u4e00' <= char <= '\u9fff' for char in word))]
        return words
    
    def calculate_similarity(self, query_words, document_content):
        """è®¡ç®—æŸ¥è¯¢è¯ä¸æ–‡æ¡£å†…å®¹çš„ç›¸ä¼¼åº¦"""
        doc_words = self.preprocess_text(document_content)
        doc_word_set = set(doc_words)
        query_word_set = set(query_words)
        
        # è®¡ç®—äº¤é›†è¯æ•°é‡
        common_words = query_word_set & doc_word_set
        if not common_words:
            return 0
        
        # è®¡ç®—æƒé‡åˆ†æ•°
        score = len(common_words)
        
        # è€ƒè™‘è¯é¢‘æƒé‡
        doc_word_count = Counter(doc_words)
        for word in common_words:
            score += doc_word_count.get(word, 0) * 0.1
            
        return score
    
    def extract_relevant_sentences(self, query_words, content, max_sentences=3):
        """ä»æ–‡æ¡£å†…å®¹ä¸­æå–ä¸æŸ¥è¯¢ç›¸å…³çš„å¥å­"""
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', content)
        sentence_scores = []
        
        for sentence in sentences:
            sentence = sentence.strip()
            if len(sentence) < 5:  # è¿‡æ»¤å¤ªçŸ­çš„å¥å­
                continue
                
            sentence_words = set(self.preprocess_text(sentence))
            query_word_set = set(query_words)
            common_words = sentence_words & query_word_set
            
            if common_words:
                # è®¡ç®—å¥å­å¾—åˆ†
                score = len(common_words) / len(query_word_set) if query_word_set else 0
                sentence_scores.append((score, sentence))
        
        # æŒ‰å¾—åˆ†æ’åºå¹¶è¿”å›å‰å‡ ä¸ªå¥å­
        sentence_scores.sort(reverse=True)
        return [sentence for score, sentence in sentence_scores[:max_sentences] if score > 0]
    
    def search_knowledge_base(self, query, knowledge_base_id, documents, top_k=5):
        """åœ¨æŒ‡å®šçŸ¥è¯†åº“ä¸­æœç´¢ç›¸å…³æ–‡æ¡£"""
        query_words = self.preprocess_text(query)
        if not query_words:
            return []
        
        # ç­›é€‰å±äºæŒ‡å®šçŸ¥è¯†åº“çš„æ–‡æ¡£
        kb_documents = [doc for doc in documents if doc['knowledge_id'] == knowledge_base_id]
        
        if not kb_documents:
            return []
        
        # è®¡ç®—æ¯ä¸ªæ–‡æ¡£çš„ç›¸ä¼¼åº¦
        scored_docs = []
        for doc in kb_documents:
            content = doc.get('content', '')
            if not content:
                continue
                
            similarity = self.calculate_similarity(query_words, content)
            if similarity > 0:
                scored_docs.append({
                    'document': doc,
                    'similarity': similarity,
                    'relevant_sentences': self.extract_relevant_sentences(query_words, content)
                })
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        scored_docs.sort(key=lambda x: x['similarity'], reverse=True)
        return scored_docs[:top_k]
    
    def generate_answer(self, query, search_results, knowledge_base_name):
        """åŸºäºæœç´¢ç»“æœç”Ÿæˆç­”æ¡ˆ (ä¼˜åŒ–ç‰ˆï¼Œç±»ä¼¼ask.pyçš„é£æ ¼)"""
        if not search_results:
            return f"æŠ±æ­‰ï¼Œåœ¨çŸ¥è¯†åº“ã€Œ{knowledge_base_name}ã€ä¸­æ²¡æœ‰æ‰¾åˆ°ä¸ã€Œ{query}ã€ç›¸å…³çš„ä¿¡æ¯ã€‚\n\nğŸ’¡ å»ºè®®ï¼š\nâ€¢ å°è¯•ä½¿ç”¨ä¸åŒçš„å…³é”®è¯\nâ€¢ ä¸Šä¼ æ›´å¤šç›¸å…³æ–‡æ¡£\nâ€¢ æ£€æŸ¥è¾“å…¥çš„é—®é¢˜æ˜¯å¦å‡†ç¡®"
        
        # æå–æŸ¥è¯¢å…³é”®è¯ç”¨äºçªå‡ºæ˜¾ç¤º
        query_keywords = set(self.preprocess_text(query))
        
        # æ„å»ºè¯¦ç»†ç­”æ¡ˆ (å‚è€ƒask.pyçš„æ ¼å¼)
        answer = f"å…³äºã€Œ{query}ã€çš„ç›¸å…³ä¿¡æ¯ï¼š\n\n"
        
        for i, result in enumerate(search_results, 1):
            doc = result['document']
            similarity = result['similarity']
            relevant_sentences = result['relevant_sentences']
            
            # æ–‡æ¡£ä¿¡æ¯
            answer += f"ğŸ“„ æ¥æºï¼š{doc['original_name']} (å…³é”®è¯åŒ¹é…æ•°: {int(similarity)})\n"
            
            # æ·»åŠ ç›¸å…³å†…å®¹
            if relevant_sentences:
                answer += "é‡ç‚¹å†…å®¹ï¼š\n"
                for sentence in relevant_sentences:
                    if sentence.strip():
                        answer += f"â€¢ {sentence.strip()}\n"
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç‰¹åˆ«ç›¸å…³çš„å¥å­ï¼Œæ˜¾ç¤ºæ–‡æ¡£æ‘˜è¦
                content = doc.get('content', '')
                if content:
                    # å¯»æ‰¾åŒ…å«å…³é”®è¯çš„å¥å­
                    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', content)
                    relevant_found = []
                    for sentence in sentences:
                        if any(keyword in sentence for keyword in query_keywords):
                            relevant_found.append(sentence.strip())
                            if len(relevant_found) >= 3:
                                break
                    
                    if relevant_found:
                        answer += "ç›¸å…³å†…å®¹ï¼š\n"
                        for sentence in relevant_found:
                            if sentence:
                                answer += f"â€¢ {sentence}\n"
                    else:
                        content_preview = content[:200].strip()
                        if content_preview:
                            answer += f"å†…å®¹æ‘˜è¦ï¼š{content_preview}{'...' if len(content) > 200 else ''}\n"
            
            answer += "\n"
        
        # æ·»åŠ æ™ºèƒ½å»ºè®®
        if len(search_results) == 1:
            answer += "ğŸ’¡ æç¤ºï¼šæ‰¾åˆ°1ä¸ªç›¸å…³æ–‡æ¡£ï¼Œå¦‚éœ€æ›´è¯¦ç»†ä¿¡æ¯ï¼Œå»ºè®®æŸ¥é˜…å®Œæ•´æ–‡æ¡£æˆ–ä¸Šä¼ æ›´å¤šç›¸å…³èµ„æ–™ã€‚"
        else:
            answer += f"ğŸ’¡ æç¤ºï¼šæ‰¾åˆ°{len(search_results)}ä¸ªç›¸å…³æ–‡æ¡£ï¼Œå»ºè®®ç»“åˆæŸ¥çœ‹ä»¥è·å¾—æ›´å…¨é¢çš„äº†è§£ã€‚"
        
        return answer

# å®ä¾‹åŒ–é—®ç­”ç³»ç»Ÿ
qa_system = IntelligentQA()

# æµ‹è¯•è¿æ¥æ¥å£
@app.route('/api/test', methods=['GET'])
def test_connection():
    try:
        return jsonify({
            'message': 'æœåŠ¡å™¨è¿è¡Œæ­£å¸¸',
            'status': 'ok',
            'database': 'file_storage',
            'knowledge_bases_count': len(knowledge_bases),
            'documents_count': len(documents)
        }), 200
    except Exception as e:
        return jsonify({'error': f'æœåŠ¡å™¨æµ‹è¯•å¤±è´¥: {str(e)}'}), 500

# è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯
@app.route('/api/stats', methods=['GET'])
def get_stats():
    try:
        total_size = 0
        for doc in documents:
            total_size += doc.get('file_size', 0)
        
        return jsonify({
            'knowledge_bases_count': len(knowledge_bases),
            'documents_count': len(documents),
            'total_file_size': total_size,
            'storage_type': 'local_file'
        }), 200
    except Exception as e:
        return jsonify({'error': f'è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}'}), 500

# ------------------------------
# 3. æ™ºèƒ½é—®ç­”æ¥å£
# ------------------------------

# æ™ºèƒ½é—®ç­”æ¥å£ï¼ˆé›†æˆå¤§æ¨¡å‹ï¼‰
@app.route('/api/query', methods=['POST'])
def intelligent_query():
    try:
        data = request.get_json()
        if not data:
            return jsonify({'error': 'è¯·æ±‚æ•°æ®ä¸ºç©º'}), 400
        
        query = data.get('query', '').strip()
        knowledge_base_id = data.get('knowledge_base_id', '').strip()
        
        if not query:
            return jsonify({'error': 'æŸ¥è¯¢å†…å®¹ä¸èƒ½ä¸ºç©º'}), 400
        
        if not knowledge_base_id:
            return jsonify({'error': 'çŸ¥è¯†åº“IDä¸èƒ½ä¸ºç©º'}), 400
        
        # æ£€æŸ¥çŸ¥è¯†åº“æ˜¯å¦å­˜åœ¨
        knowledge_base = None
        for kb in knowledge_bases:
            if kb['_id'] == knowledge_base_id:
                knowledge_base = kb
                break
        
        if not knowledge_base:
            return jsonify({'error': 'æŒ‡å®šçš„çŸ¥è¯†åº“ä¸å­˜åœ¨'}), 404
        
        # æ£€æŸ¥çŸ¥è¯†åº“æ˜¯å¦æœ‰æ–‡æ¡£
        kb_documents = [doc for doc in documents if doc['knowledge_id'] == knowledge_base_id]
        if not kb_documents:
            return jsonify({
                'answer': f"çŸ¥è¯†åº“ã€Œ{knowledge_base['name']}ã€ä¸­æš‚æ— æ–‡æ¡£ã€‚è¯·å…ˆä¸Šä¼ ç›¸å…³æ–‡æ¡£åå†è¿›è¡ŒæŸ¥è¯¢ã€‚",
                'llm_answer': "",
                'sources': [],
                'knowledge_base_name': knowledge_base['name']
            }), 200
        
        print(f"ğŸ” æ”¶åˆ°æŸ¥è¯¢è¯·æ±‚: \"{query}\" - çŸ¥è¯†åº“: {knowledge_base['name']}")
        
        # ä½¿ç”¨æ™ºèƒ½é—®ç­”ç³»ç»Ÿæœç´¢ç›¸å…³æ–‡æ¡£
        search_results = qa_system.search_knowledge_base(
            query=query,
            knowledge_base_id=knowledge_base_id,
            documents=documents,
            top_k=5
        )
        
        # ç”Ÿæˆä¼ ç»ŸåŒ¹é…ç­”æ¡ˆ
        traditional_answer = qa_system.generate_answer(
            query=query,
            search_results=search_results,
            knowledge_base_name=knowledge_base['name']
        )
        
        # å‡†å¤‡å¤§æ¨¡å‹é—®ç­”
        llm_answer = ""
        try:
            # æ„å»ºä¸Šä¸‹æ–‡å†…å®¹
            context_content = ""
            if search_results:
                context_content = "ç›¸å…³æ–‡æ¡£å†…å®¹ï¼š\n\n"
                for i, result in enumerate(search_results[:3], 1):  # åªå–å‰3ä¸ªæœ€ç›¸å…³çš„ç»“æœ
                    doc = result['document']
                    context_content += f"æ–‡æ¡£{i}ï¼šã€Š{doc['original_name']}ã€‹\n"
                    
                    # æ·»åŠ ç›¸å…³å¥å­æˆ–å†…å®¹æ‘˜è¦
                    if result['relevant_sentences']:
                        for sentence in result['relevant_sentences'][:2]:  # æ¯ä¸ªæ–‡æ¡£æœ€å¤š2ä¸ªå¥å­
                            context_content += f"- {sentence.strip()}\n"
                    else:
                        # å¦‚æœæ²¡æœ‰ç›¸å…³å¥å­ï¼Œæ·»åŠ å†…å®¹æ‘˜è¦
                        content = doc.get('content', '')
                        if content:
                            preview = content[:300].strip()
                            context_content += f"- {preview}{'...' if len(content) > 300 else ''}\n"
                    context_content += "\n"
            else:
                context_content = "æš‚æ— ç›¸å…³æ–‡æ¡£å†…å®¹ã€‚"
            
            # è·å–çŸ¥è¯†åº“çš„è‡ªå®šä¹‰æç¤ºè¯
            system_prompt = knowledge_base.get('prompt', 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ¥è¯†åº“åŠ©æ‰‹ï¼Œè¯·æ ¹æ®æä¾›çš„æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚')
            
            # æ„å»ºå®Œæ•´çš„æç¤ºè¯
            full_prompt = f"{system_prompt}\n\n{context_content}\n\nè¯·åŸºäºä»¥ä¸Šå†…å®¹å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯šå®è¯´æ˜ï¼Œå¹¶æä¾›ä¸€èˆ¬æ€§çš„å»ºè®®ã€‚"
            
            # è°ƒç”¨è±†åŒ…å¤§æ¨¡å‹
            completion = ark_client.chat.completions.create(
                model=ARK_MODEL,
                messages=[
                    {"role": "system", "content": full_prompt},
                    {"role": "user", "content": query}
                ],
                max_tokens=1000,
                temperature=0.7
            )
            
            llm_answer = completion.choices[0].message.content
            print(f"âœ… å¤§æ¨¡å‹å›ç­”ç”ŸæˆæˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ å¤§æ¨¡å‹è°ƒç”¨å¤±è´¥: {e}")
            llm_answer = f"æŠ±æ­‰ï¼Œå¤§æ¨¡å‹æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚é”™è¯¯ä¿¡æ¯ï¼š{str(e)}"
        
        # æ„å»ºè¿”å›çš„æ¥æºä¿¡æ¯
        sources = []
        for result in search_results:
            doc = result['document']
            sources.append({
                'document_name': doc['original_name'],
                'similarity': result['similarity'],
                'relevant_content': result['relevant_sentences'][:2]  # åªè¿”å›å‰2ä¸ªç›¸å…³å¥å­
            })
        
        print(f"âœ… æŸ¥è¯¢å®Œæˆï¼Œæ‰¾åˆ° {len(search_results)} ä¸ªç›¸å…³æ–‡æ¡£")
        
        return jsonify({
            'answer': traditional_answer,
            'llm_answer': llm_answer,
            'sources': sources,
            'knowledge_base_name': knowledge_base['name'],
            'query': query
        }), 200
        
    except Exception as e:
        print(f"âŒ æ™ºèƒ½é—®ç­”å¤±è´¥: {e}")
        return jsonify({'error': f'æ™ºèƒ½é—®ç­”å¤±è´¥: {str(e)}'}), 500

# ------------------------------
# 4. æ–‡ä»¶ä¸Šä¼ ä¸å¤„ç†æ¥å£ (ç§»åŠ¨ç°æœ‰çš„ä¸Šä¼ æ¥å£åˆ°è¿™é‡Œ)
# ------------------------------

# ------------------------------
# 5. é™æ€æ–‡ä»¶æœåŠ¡
# ------------------------------

# æä¾›å‰ç«¯HTMLé¡µé¢
@app.route('/')
def index():
    return app.send_static_file('pagev1.html') if os.path.exists('pagev1.html') else "æœåŠ¡å™¨è¿è¡Œä¸­ï¼Œè¯·è®¿é—® /pagev1.html"

@app.route('/pagev1.html')
def frontend():
    if os.path.exists('pagev1.html'):
        with open('pagev1.html', 'r', encoding='utf-8') as f:
            return f.read()
    else:
        return "å‰ç«¯é¡µé¢æœªæ‰¾åˆ°", 404

@app.route('/test_public_access.html')
def test_page():
    if os.path.exists('test_public_access.html'):
        with open('test_public_access.html', 'r', encoding='utf-8') as f:
            return f.read()
    else:
        return "æµ‹è¯•é¡µé¢æœªæ‰¾åˆ°", 404

@app.route('/pic/<filename>')
def serve_images(filename):
    """æä¾›å›¾ç‰‡æ–‡ä»¶æœåŠ¡"""
    try:
        pic_path = os.path.join('pic', filename)
        if os.path.exists(pic_path):
            with open(pic_path, 'rb') as f:
                content = f.read()
            # æ ¹æ®æ–‡ä»¶æ‰©å±•åè®¾ç½®æ­£ç¡®çš„MIMEç±»å‹
            if filename.lower().endswith('.png'):
                return content, 200, {'Content-Type': 'image/png'}
            elif filename.lower().endswith('.jpg') or filename.lower().endswith('.jpeg'):
                return content, 200, {'Content-Type': 'image/jpeg'}
            elif filename.lower().endswith('.gif'):
                return content, 200, {'Content-Type': 'image/gif'}
            else:
                return content, 200, {'Content-Type': 'image/octet-stream'}
        else:
            return "å›¾ç‰‡æœªæ‰¾åˆ°", 404
    except Exception as e:
        print(f"æä¾›å›¾ç‰‡æœåŠ¡å¤±è´¥: {e}")
        return "å›¾ç‰‡æœåŠ¡é”™è¯¯", 500

if __name__ == '__main__':
    # åˆå§‹åŒ–æ•°æ®å­˜å‚¨
    print("ğŸš€ å¯åŠ¨æ™ºèƒ½çŸ¥è¯†åº“æ£€ç´¢ç³»ç»Ÿ...")
    init_data_storage()
    
    print(f"ğŸ“š å½“å‰çŸ¥è¯†åº“æ•°é‡: {len(knowledge_bases)}")
    print(f"ğŸ“„ å½“å‰æ–‡æ¡£æ•°é‡: {len(documents)}")
    print("=" * 50)
    
    # å¯åŠ¨Flaskåº”ç”¨
    print("ğŸŒ æœåŠ¡å™¨å¯åŠ¨ä¸­...")
    print("ğŸ’¡ æœ¬åœ°è®¿é—®åœ°å€: http://localhost:5000")
    print("ğŸŒ å…¬ç½‘è®¿é—®åœ°å€: http://152.136.167.211:5000")
    print("ï¿½ å‰ç«¯é¡µé¢: http://152.136.167.211:5000/pagev1.html")
    print("ï¿½ğŸ“¡ APIæ¥å£åœ°å€: http://152.136.167.211:5000/api")
    print("=" * 50)
    
    app.run(
        host='0.0.0.0',    # ç›‘å¬æ‰€æœ‰ç½‘ç»œæ¥å£ï¼ˆå…è®¸å…¬ç½‘è®¿é—®ï¼‰
        port=5000,         # ç«¯å£å·
        debug=False,       # ç”Ÿäº§ç¯å¢ƒå…³é—­è°ƒè¯•æ¨¡å¼
        threaded=True      # æ”¯æŒå¤šçº¿ç¨‹
    )